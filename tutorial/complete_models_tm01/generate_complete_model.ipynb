{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bde8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "05/23/2023; Tim Marshall; tmchmbusiness@gmail.com\n",
    "\n",
    "Script to build complete Markov state models for TC5b generated using Folding@Home platform\n",
    "\n",
    "server@vav22:~/server2/data/PROJ16959/RUN9/CLONE2 - gens 128-571 (640-2860 ns) = 2.22 us Eaxh gen is 5 ns, which snapshots saved ever 100 ps\n",
    "\"\"\"\n",
    "# standard dependencies\n",
    "import os, sys, subprocess\n",
    "# special dependencies\n",
    "import pyemma\n",
    "import numpy as np\n",
    "\n",
    "# specify raw data directory\n",
    "data_dir = f'./../TC5b-data/'\n",
    "\n",
    "### BOOLS ###\n",
    "# save? \n",
    "SAVE = False\n",
    "\n",
    "# random 50% subsample\n",
    "BOOT = False\n",
    "\n",
    "# quick, 1 trajectory test run\n",
    "QUICK = True\n",
    "\n",
    "# model scoring\n",
    "# disabled by default due to resource requirements\n",
    "score_features = False\n",
    "score_msm = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ad10c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADER ####\n",
    "\n",
    "# load in structure\n",
    "structure = os.path.join(data_dir, 'xtc_atoms.gro')\n",
    "\n",
    "# load in trajectories\n",
    "trajectories = [os.path.join(data_dir, s.strip()) for s in \"\"\"p16959r9c29-whole.xtc \n",
    "p16959r9c83-whole.xtc \n",
    "p16959r9c100-whole.xtc\n",
    "p16959r9c109-whole.xtc\n",
    "p16959r9c127-whole.xtc\n",
    "p16959r9c151-whole.xtc\n",
    "p16959r9c166-whole.xtc\n",
    "p16959r9c219-whole.xtc\n",
    "p16959r9c312-whole.xtc\n",
    "p16959r9c394-whole.xtc\n",
    "p16959r9c631-whole.xtc\n",
    "p16959r9c726-whole.xtc\"\"\".split('\\n')]\n",
    "\n",
    "### SPECIAL CALCULATION CASE ###\n",
    "# this section yields quick/special models\n",
    "# use carefully\n",
    "# if you wish to bootstrap your data\n",
    "if BOOT:\n",
    "    import random\n",
    "    trajectories = random.sample(trajectories, int(len(trajectories)*0.50))\n",
    "# single trajectory testing\n",
    "if QUICK:\n",
    "    trajectories = trajectories[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67fe485d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurization complete\n"
     ]
    }
   ],
   "source": [
    "### FEATURIZER ####\n",
    "\n",
    "# load in structure as pyemma object for selecting features\n",
    "feat = pyemma.coordinates.featurizer(structure)\n",
    "\n",
    "# add CA-CA pairwise distances with nearest neighbor exclusion\n",
    "# this was selected as the best performing feature set based on VAMP-2 scoring\n",
    "feat.add_distances_ca()\n",
    "feat_data = pyemma.coordinates.load(trajectories, features=feat)\n",
    "\n",
    "# SAVE\n",
    "feat_name_save = f'featurized_data'\n",
    "if SAVE:\n",
    "    np.save(feat_name_save, feat_data)\n",
    "\n",
    "### SCORE FEATRURES ###\n",
    "\n",
    "# score feature set\n",
    "validation_fraction = 0.50    #fraction of training/testing split\n",
    "number_of_splits = 10    #number of times to perform calc, for error purposes\n",
    "if score_features:\n",
    "    nval = int(len(feat_data) * validation_fraction)\n",
    "    scores = np.zeros(number_of_splits)\n",
    "\n",
    "    for n, _ in enumerate(scores):\n",
    "        ival = np.random.choice(len(feat_data), size=nval, replace=False)\n",
    "        valid = [d for i, d in enumerate(feat_data) if i not in ival]\n",
    "        vamp = pyemma.coordinates.vamp(valid, lag=lag, dim=dim, scaling = 'km')\n",
    "        scores[n] = vamp.score([d for i, d in enumerate(feat_data) if i in ival])\n",
    "    # SAVE\n",
    "    feature_score_name_save = f'feature_scores'\n",
    "    if SAVE:\n",
    "        np.save(feature_score_name_save, scores)\n",
    "print(f'featurization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cab4bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tica complete\n"
     ]
    }
   ],
   "source": [
    "### TICA ###\n",
    "\n",
    "# parameters for calculation\n",
    "dim = 4\n",
    "tica_lag = 100\n",
    "\n",
    "#feat_list = np.ndarray.tolist(feat)    #don't worry about this, Tim's paranoia with pyemma\n",
    "# perform tica\n",
    "tica = pyemma.coordinates.tica(feat_data, dim=dim, lag=tica_lag, scaling = 'km')\n",
    "\n",
    "# grab output\n",
    "tica_getoutput = tica.get_output()\n",
    "\n",
    "# SAVE\n",
    "tica_name_save = 'tica_getoutput'\n",
    "if SAVE:\n",
    "    np.save(tica_name_save, tica_getoutput)\n",
    "\n",
    "print(f'tica complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67a00e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "initialize kmeans++ centers:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "kmeans iterations:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretization complete\n"
     ]
    }
   ],
   "source": [
    "### DISCRETIZER ###\n",
    "\n",
    "# parameters for calculation\n",
    "number_of_clusters = 50\n",
    "max_iter = 100\n",
    "\n",
    "# cluster using kmeans algorithm\n",
    "cluster = pyemma.coordinates.cluster_kmeans(tica_getoutput, k=number_of_clusters, max_iter=max_iter)\n",
    "\n",
    "cluster_getoutput = cluster.get_output()\n",
    "cluster_dtrajs = cluster.dtrajs\n",
    "cluster_centers = cluster.clustercenters\n",
    "\n",
    "# SAVE\n",
    "# kmeans is weird in pyemma, so we save a bunch of potentially relevant objects in case of data corruption\n",
    "discretization_save_name = 'kmeans'\n",
    "if SAVE:\n",
    "    cluster_getoutput = cluster.get_output()\n",
    "    cluster_dtrajs = cluster.dtrajs\n",
    "    cluster_centers = cluster.clustercenters\n",
    "\n",
    "    np.save(f'{discretization_save_name}_getoutput.npy', cluster_getoutput)\n",
    "    np.save(f'{discretization_save_name}_dtrajs.npy', cluster_dtrajs)\n",
    "    np.save(f'{discretization_save_name}_centers.npy', cluster_centers)\n",
    "\n",
    "print('discretization complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5a6ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "MODEL COMPLETE\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### MSM ###\n",
    "msm_lag = 200\n",
    "\n",
    "msm = pyemma.msm.estimate_markov_model(cluster.dtrajs, msm_lag)\n",
    "\n",
    "# SAVE\n",
    "# only time it is ok to use pyemma's save function\n",
    "msm_save_name = 'msm'\n",
    "if SAVE:\n",
    "    msm.save(f'{msm_save_name}.h5',  overwrite=True)\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('MODEL COMPLETE')\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "### SCORE MSM ###\n",
    "number_of_splits = 2\n",
    "msm_scores_save_name = 'msm_scores'\n",
    "\n",
    "# dirty scoring functions, but works\n",
    "if score_msm:\n",
    "    \n",
    "    # empty lists for population\n",
    "    scores= [[] for i in range(2)]\n",
    "    split_scores = []\n",
    "    \n",
    "    # calculate score and append to list\n",
    "    for s in range(number_of_splits):\n",
    "        score = msm.score_cv(cluster.dtrajs, n=1, score_method='VAMP2')\n",
    "        split_scores.append(score[0])\n",
    "        \n",
    "    # calculate avg and std\n",
    "    kscores_avg = np.average(split_scores)\n",
    "    kscores_std = np.std(split_scores)\n",
    "\n",
    "    scores[0].append(kscores_avg)\n",
    "    scores[1].append(kscores_std)\n",
    "    \n",
    "    np.save(msm_scores_save_name, scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
